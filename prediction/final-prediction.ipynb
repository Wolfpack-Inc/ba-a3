{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "sys.path.append('..')\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from load_data import *\n",
    "\n",
    "from numpy.random import default_rng\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_part_test_data(dataframe_test, create_amount_of_random_numbers = 6, distance_of_max_length = 0):\n",
    "    \"\"\"\n",
    "    This function takes as input the df_test and creates for each engine id\n",
    "    random amount of numbers (create_amount_of_random_numbers). Then it sorts \n",
    "    those numbers and takes the lowest and biggest number (e.g. 4 and 142). It\n",
    "    uses those numbers to slice a random part.\n",
    "    \n",
    "    We also can add the parameter 'distance_of_max_length'. This parameter allows\n",
    "    us to for example set a limit of -50 of the maximum length of an engine id. If\n",
    "    the engine_id has e.g. length 230 (where the RUL is 0), we can set the limit to\n",
    "    finding random number between 0 and 180 (instead of 230).\n",
    "    \"\"\"\n",
    "    # Extract all the unique engine ids and their maximum length in the original dataframe\n",
    "    unique_engine_ids = dataframe_test.index.unique()\n",
    "    amount_of_ruls    = {engine_id : dataframe_test[dataframe_test.index == engine_id]['cycle'].max()\n",
    "                         for engine_id in unique_engine_ids}\n",
    "    \n",
    "    \n",
    "    # Loop over all engine ids and their length in the original dataframe_test\n",
    "    print('The test dataframe includes the following engine ids: {}.\\n'.format(list(unique_engine_ids)))\n",
    "    print('We sliced the test dataframe into the following slices: \\n')\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    for engine_id, max_length in amount_of_ruls.items():\n",
    "        random_numbers = np.random.randint(0, (max_length - 1 - distance_of_max_length), create_amount_of_random_numbers)\n",
    "        random_numbers_sorted = np.sort(random_numbers, axis=None)\n",
    "        print('Engine Id {} filtered on index : {}.'.format(engine_id, [random_numbers_sorted[0], random_numbers_sorted[-1]]))\n",
    "        print('This slice has a length of {}.'.format(random_numbers_sorted[-1] - random_numbers_sorted[0]))\n",
    "        print('The original total length of the engine id was {}.'.format(amount_of_ruls[engine_id]))\n",
    "        print('------------------------------------------------\\n')\n",
    "        \n",
    "        df_filtered = dataframe_test[dataframe_test.index == engine_id]\n",
    "        df_filtered = df_filtered.iloc[random_numbers_sorted[0] : random_numbers_sorted[-1]]\n",
    "        \n",
    "        new_df = new_df.append(df_filtered)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ruls(dataframe):\n",
    "    \"\"\"\n",
    "    Get the ruls of the engines\n",
    "    \"\"\"\n",
    "    # Try to drop max cycle to prevent an error\n",
    "    dataframe = dataframe.drop('max_cycle', 1, errors='ignore')\n",
    "    \n",
    "    # The max cycle of each engine\n",
    "    max_cycle = dataframe.groupby('engine_id').agg({'cycle': 'max'}).rename({'cycle': 'max_cycle'}, axis=1)\n",
    "    \n",
    "    # Add the max cycle to the dataframe\n",
    "    dataframe = dataframe.join(max_cycle, on='engine_id', )\n",
    "    \n",
    "    # Ruls are max cycle minus current cycle (plus 1)\n",
    "    ruls = (dataframe['max_cycle'] - dataframe['cycle'] + 1).values\n",
    "    \n",
    "    return ruls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_add_rul_filter_and_norm_data(percentage_test_set, path = '../data/DataTrain.txt'):\n",
    "    df = load_dataset(path)\n",
    "    df = df.set_index('engine_id')\n",
    "    \n",
    "    # Based on the analysing the slopes we found that the following sensors had\n",
    "    # showed a trend and had the highest average slope. We focus on the sensors \n",
    "    # with higher slopes because this makes it easier to distinguish the different RULs.\n",
    "    df = df[['cycle', 's4', 's3', 's17', 's7', 's12', 's2']]\n",
    "    df.loc[:, 'rul'] = get_ruls(df)\n",
    "    \n",
    "    # Calculate percentage test set\n",
    "    unique_engine_ids = df.index.unique()\n",
    "    \n",
    "    engine_ids_for_test_set = default_rng().choice(unique_engine_ids,\n",
    "                                                   size = int(max(unique_engine_ids) * percentage_test_set), \n",
    "                                                   replace=False)\n",
    "    \n",
    "    # Split data into df_train and df_test\n",
    "    df_train = df[~df.index.isin(engine_ids_for_test_set)]\n",
    "    df_test  = df[df.index.isin(engine_ids_for_test_set)]\n",
    "    \n",
    "    # Normalize both dataframes\n",
    "    scaler = StandardScaler()\n",
    "    df_train.iloc[:, 1:-1] = scaler.fit_transform(df_train.iloc[:, 1:-1])\n",
    "    df_test.iloc[:, 1:-1]  = scaler.transform(df_test.iloc[:, 1:-1])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slopes_all_engine(training_dataframe):\n",
    "    \"\"\"\n",
    "    Get the sensor slopes of all engines.\n",
    "    \"\"\"\n",
    "    def get_training_data(dataframe, engine_id, sensor_cols):\n",
    "        # X data\n",
    "        X = dataframe.loc[engine_id, 'rul'].values\n",
    "        X = X.reshape(-1, 1)\n",
    "\n",
    "        # y data\n",
    "        y = dataframe.loc[engine_id, sensor_cols].values\n",
    "\n",
    "        return (X, y)\n",
    "    \n",
    "    def slopes_of_engine(X, y):\n",
    "        \"\"\"\n",
    "        Fit a linear model on the sensor values of one engine\n",
    "        \"\"\"\n",
    "        # Create a linear model\n",
    "        linear_model = LinearRegression()\n",
    "\n",
    "        # Fit the model\n",
    "        linear_model.fit(X, y)\n",
    "\n",
    "        # Get slopes\n",
    "        slopes = linear_model.coef_[:,0]\n",
    "\n",
    "        return slopes\n",
    "    \n",
    "    # Loop over all the engines and calculate the slopes.\n",
    "    engine_slopes = {}\n",
    "    sensor_cols = training_dataframe.columns[1: -1].tolist()\n",
    "    \n",
    "    for engine_id in training_dataframe.index.unique():\n",
    "        X, y = get_training_data(training_dataframe, engine_id, sensor_cols)\n",
    "        slopes = slopes_of_engine(X, y)\n",
    "        \n",
    "        engine_slopes[engine_id] = slopes\n",
    "        \n",
    "    df_engine_slopes = pd.DataFrame(engine_slopes).T\n",
    "\n",
    "    df_engine_slopes.columns = sensor_cols\n",
    "    df_engine_slopes.index.name = 'engine_id'\n",
    "\n",
    "    return df_engine_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(dataframe_with_engine_slopes, dataframe_training, dataframe_testing, \n",
    "                n_components = 3, keep_rul_in_test = True):\n",
    "    \"\"\"\n",
    "    Here we will perform the PCA on the training and test set.\n",
    "    \"\"\"\n",
    "    # Fit the PCA on the engine slopes to reduce the dimensionality.\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(dataframe_with_engine_slopes)\n",
    "        \n",
    "    # Apply PCA on the dataframes    \n",
    "    matrix_training = np.column_stack([dataframe_training[['cycle', 'rul']].values, pca.transform(dataframe_training.iloc[:, 1:-1])])   \n",
    "    df_pca_training = pd.DataFrame(matrix_training, index=dataframe_training.index, columns=['cycle', 'rul', 'pca1', 'pca2', 'pca3'])\n",
    "        \n",
    "    if keep_rul_in_test == True:\n",
    "        matrix_testing  = np.column_stack([dataframe_testing[['cycle', 'rul']].values, pca.transform(dataframe_testing.iloc[:, 1:-1])])\n",
    "        df_pca_testing  = pd.DataFrame(matrix_testing, index=dataframe_testing.index, columns=['cycle', 'rul', 'pca1', 'pca2', 'pca3'])\n",
    "\n",
    "    else: \n",
    "        matrix_testing  = np.column_stack([dataframe_testing[['cycle']].values, pca.transform(dataframe_testing.iloc[:, 1:])])\n",
    "        df_pca_testing  = pd.DataFrame(matrix_testing, index=dataframe_testing.index, columns=['cycle', 'pca1', 'pca2', 'pca3'])\n",
    "\n",
    "    return df_pca_training, df_pca_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_health_indictor_model(dataframe_training_with_pca_values, high_rul = 250, low_rul = 5):\n",
    "    \"\"\"\n",
    "    This function applies sensor fusing to the training data and returns a\n",
    "    trained model to make predictions.\n",
    "    \"\"\"\n",
    "    # Extract ruls\n",
    "    ruls     = dataframe_training_with_pca_values['rul'].values\n",
    "    \n",
    "    # Extract rows\n",
    "    idx_high_health = [ruls > high_rul][0]\n",
    "    idx_low_health  = [ruls <= low_rul][0]\n",
    "    \n",
    "    # PCA to perform sensor fusing on\n",
    "    high_health_data = dataframe_training_with_pca_values.loc[idx_high_health, ['pca1', 'pca2', 'pca3']]\n",
    "    low_health_data  = dataframe_training_with_pca_values.loc[idx_low_health, ['pca1', 'pca2', 'pca3']]\n",
    "    \n",
    "    # concatenate high HI and Low HI data\n",
    "    X_health = np.concatenate((high_health_data, low_health_data),axis=0)\n",
    "\n",
    "    # target for the fused signal [ just 0 or 1 for failed ans healthy]\n",
    "    y_one = np.ones(high_health_data.shape[0])\n",
    "    y_zero = np.zeros(low_health_data.shape[0])\n",
    "\n",
    "    # concatenate high HI and Low HI target\n",
    "    y_health = np.concatenate((y_one, y_zero),axis=0)\n",
    "    \n",
    "    # Linear regression\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_health, y_health)\n",
    "    \n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_exponential_fits(dataframe_with_health_index):\n",
    "    def exp_func(x, a, b):\n",
    "        return a * (np.exp(b * -x)-1)\n",
    "\n",
    "    def find_exp_params(dataframe):\n",
    "        exp_params = np.zeros((dataframe.index.nunique(), 2))\n",
    "\n",
    "        # Loop through the engines\n",
    "        for idx, (engine_id, engine) in enumerate(dataframe.groupby('engine_id')):\n",
    "            x = engine['rul']\n",
    "            y = savgol_filter(engine['hi_pred'], 25, 1)\n",
    "\n",
    "            popt, _ = curve_fit(exp_func, x, y)\n",
    "\n",
    "            exp_params[idx, :] = popt\n",
    "\n",
    "        return exp_params\n",
    "\n",
    "    def get_exponential(timestep, row):\n",
    "        return exp_func(timestep['rul'], *exp_params[row, :])\n",
    "\n",
    "    exp_params = find_exp_params(dataframe_with_health_index)\n",
    "\n",
    "    dataframe_with_health_index['exp'] = 0\n",
    "\n",
    "    for index, engine_id in enumerate(dataframe_with_health_index.index.unique()):\n",
    "        indexes = dataframe_with_health_index[dataframe_with_health_index.index == engine_id].index\n",
    "        dataframe_with_health_index.loc[indexes, 'exp'] = dataframe_with_health_index.loc[indexes].apply(lambda x: get_exponential(x, index), axis =1)\n",
    "    \n",
    "    return dataframe_with_health_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rul_based_on_weighted_ssd(list_with_ssd_and_rul, extract_best_x = 5):\n",
    "    \"\"\"\n",
    "    This function makes based on a nested list [(ssd1, rul1), ... , (ssdN, rulN)]\n",
    "    a weighted prediction based on the ssd.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dataframe of the nested list\n",
    "    df_ssd_and_rul = pd.DataFrame(list_with_ssd_and_rul, columns=['ssd', 'rul'])\n",
    "        \n",
    "    # Sort the dataframe based on the ssd and extract top X (extract_best_x)\n",
    "    df_ssd_and_rul = df_ssd_and_rul.sort_values('ssd').iloc[ : extract_best_x]\n",
    "    \n",
    "    # Add percentage ssd of total\n",
    "    sum_ssd = sum(1 / df_ssd_and_rul['ssd'].values)   \n",
    "    df_ssd_and_rul['percentage_of_total'] = (1 / df_ssd_and_rul['ssd']) / sum_ssd\n",
    "    \n",
    "    # Make weighted predictions\n",
    "    weighted_prediction = sum(df_ssd_and_rul['rul'] * df_ssd_and_rul['percentage_of_total'])\n",
    "    \n",
    "    # Return prediction\n",
    "    return weighted_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_for_engineid_lowest_loss(dataframe_training, \n",
    "                                  dataframe_testing_engineid,\n",
    "                                  make_prediction_only = False):\n",
    "    \n",
    "    results = list()\n",
    "    length    = len(dataframe_testing_engineid)\n",
    "    \n",
    "    # We will look in each engine (of dataframe_training) for the lowest loss.\n",
    "    # When we find it, we will store it with the predicted RUL. This allows us \n",
    "    # to make predictions taking into account all the engineids.\n",
    "    for engine_id in dataframe_training.index.unique():\n",
    "        filtered_df = dataframe_training[dataframe_training.index == engine_id]\n",
    "        best_loss   = np.inf\n",
    "        best_train_slice = list()\n",
    "        \n",
    "        # Loop over each array in the filtered dataframe and try to find the \n",
    "        # best 'exp' where the loss is the lowest.\n",
    "        for row_index in range(0, len(filtered_df) - length):\n",
    "            train_slice = filtered_df.iloc[row_index : (row_index+length)]\n",
    "            train_health_index = train_slice['exp'].values\n",
    "            test_health_index  = dataframe_testing_engineid['hi_pred'].values\n",
    "\n",
    "            loss = np.sum((train_health_index - test_health_index) ** 2)\n",
    "\n",
    "            if loss < best_loss:\n",
    "                best_loss        = loss\n",
    "                best_train_slice = train_slice\n",
    "                \n",
    "        # If we couldn't find any good fit on the 'exp' in this engine id, skip the\n",
    "        # appending to the results.\n",
    "        if best_loss == np.inf:\n",
    "            continue\n",
    "            \n",
    "        # Add the result (loss and the RUL)\n",
    "        results.append([best_loss, int(best_train_slice.iloc[-1]['rul'])])\n",
    "        \n",
    "    # Make a weighted prediction based on the nested list\n",
    "    weighted_prediction = predict_rul_based_on_weighted_ssd(results)\n",
    "    \n",
    "    if make_prediction_only == False:\n",
    "        best_rul_difference = abs(int(dataframe_testing_engineid.iloc[-1]['rul']) - weighted_prediction)\n",
    "\n",
    "        print('Best loss:      ', best_loss)\n",
    "        print('Train RUL:      ', int(weighted_prediction))\n",
    "        print('Test RUL:       ', int(dataframe_testing_engineid.iloc[-1]['rul']))\n",
    "        print('RUL difference: ', best_rul_difference)\n",
    "        print('\\n')    \n",
    "            \n",
    "        return best_rul_difference\n",
    "    \n",
    "    else:\n",
    "        return weighted_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prediction(dataframe_training, dataframe_schedule):\n",
    "    \"\"\"\n",
    "    This function makes a prediction on the dataframe_schedule using the\n",
    "    dataframe_training.\n",
    "    \n",
    "    To make a prediction, we apply the following steps:\n",
    "    1. Extract the relevant columns from both tables.\n",
    "    2. Calculate the slopes of the dataframe_training.\n",
    "    3. Apply PCA and transform both dataframe_training and dataframe_schedule.\n",
    "    4. Train a linear model to predict the health indicators.\n",
    "    5. Predict the health indicators (hi_pred) of both tables.\n",
    "    6. Add fit an exponential model on the hi_pred of dataframe_training (exp).\n",
    "    7. Try to fit each engine_ids hi_pred in the dataframe_schedule on the best\n",
    "       suiting 'exp'. Based on the best fit we will predict the RUL.\n",
    "    \"\"\"\n",
    "    # Extract the relevant columns from both tables\n",
    "    columns = ['cycle', 's4', 's3', 's17', 's7', 's12', 's2', 'rul']\n",
    "    \n",
    "    dataframe_training = dataframe_training[columns]\n",
    "    dataframe_schedule = dataframe_schedule[columns[: -1]]\n",
    "            \n",
    "    # Calculate slopes of the dataframe_training\n",
    "    dataframe_training_slopes = slopes_all_engine(dataframe_training)\n",
    "    \n",
    "    # Reduce dimensionalities with PCA\n",
    "    dataframe_training_pca, dataframe_schedule_pca = perform_pca(dataframe_training_slopes, \n",
    "                                                                 dataframe_training, \n",
    "                                                                 dataframe_schedule, \n",
    "                                                                 keep_rul_in_test = False)\n",
    "    \n",
    "    # Train linear model\n",
    "    trained_model = train_health_indictor_model(dataframe_training_pca)\n",
    "        \n",
    "    # Predict health indicator\n",
    "    dataframe_training['hi_pred'] = trained_model.predict(dataframe_training_pca[['pca1', 'pca2', 'pca3']])\n",
    "    dataframe_schedule['hi_pred'] = trained_model.predict(dataframe_schedule_pca[['pca1', 'pca2', 'pca3']])\n",
    "    \n",
    "    # Add exponential fit\n",
    "    dataframe_training = add_exponential_fits(dataframe_training)\n",
    "    \n",
    "    # Make predictions\n",
    "    results = {}\n",
    "    \n",
    "    for engineid in dataframe_training.index.unique():\n",
    "        results[engineid] = find_for_engineid_lowest_loss(dataframe_training, \n",
    "                                                          dataframe_schedule[dataframe_schedule.index == engineid],\n",
    "                                                          make_prediction_only = True)    \n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 259 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create split\n",
    "df_training, df_testing = load_add_rul_filter_and_norm_data(percentage_test_set=0.2)\n",
    "\n",
    "# Extract random slice of dataframe\n",
    "# df_testing = extract_part_test_data(df_testing, create_amount_of_random_numbers = 6, distance_of_max_length = 50)\n",
    "\n",
    "# Extract slopes\n",
    "df_slopes = slopes_all_engine(df_training)\n",
    "\n",
    "# Reduce the dimensionalities to 3 dimensions\n",
    "df_training_pca, df_testing_pca = perform_pca(df_slopes, df_training, df_testing, keep_rul_in_test = True)\n",
    "\n",
    "# Train model to predict Health Indicator\n",
    "gekke_model = train_health_indictor_model(df_training_pca)\n",
    "\n",
    "# Add health indicator\n",
    "df_training_pca['hi_pred'] = gekke_model.predict(df_training_pca[['pca1', 'pca2', 'pca3']])\n",
    "df_testing_pca['hi_pred']  = gekke_model.predict(df_testing_pca[['pca1', 'pca2', 'pca3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add exp model\n",
    "df_training_with_hi_and_exp = add_exponential_fits(df_training_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss:       inf\n",
      "Train RUL:       14\n",
      "Test RUL:        1\n",
      "RUL difference:  13.56544729613006\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 5 rul difference: 13.56544729613006.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       13\n",
      "Test RUL:        1\n",
      "RUL difference:  12.088934918717218\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 7 rul difference: 12.088934918717218.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       20\n",
      "Test RUL:        1\n",
      "RUL difference:  19.374095857036828\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 10 rul difference: 19.374095857036828.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.3979587747797342\n",
      "Train RUL:       7\n",
      "Test RUL:        1\n",
      "RUL difference:  6.7775423082784325\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 14 rul difference: 6.7775423082784325.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       1\n",
      "Test RUL:        1\n",
      "RUL difference:  0.9999999999999996\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 16 rul difference: 0.9999999999999996.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       4\n",
      "Test RUL:        1\n",
      "RUL difference:  3.90970703294452\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 25 rul difference: 3.90970703294452.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       2.946788379040118\n",
      "Train RUL:       12\n",
      "Test RUL:        1\n",
      "RUL difference:  11.625668221207226\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 26 rul difference: 11.625668221207226.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       10.569003332107027\n",
      "Train RUL:       3\n",
      "Test RUL:        1\n",
      "RUL difference:  2.6884407242169432\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 30 rul difference: 2.6884407242169432.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.9695757851032571\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.192744655469688\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 37 rul difference: 1.192744655469688.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       6.147410954634301\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.8243521030679801\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 45 rul difference: 1.8243521030679801.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       13\n",
      "Test RUL:        1\n",
      "RUL difference:  12.069244160846315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 54 rul difference: 12.069244160846315.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       1\n",
      "Test RUL:        1\n",
      "RUL difference:  0.9999999999999998\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 56 rul difference: 0.9999999999999998.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.053692950242049\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 66 rul difference: 1.053692950242049.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 67 rul difference: 1.0.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       0\n",
      "Test RUL:        1\n",
      "RUL difference:  1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 69 rul difference: 1.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       39\n",
      "Test RUL:        1\n",
      "RUL difference:  38.43918716875481\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 78 rul difference: 38.43918716875481.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.8273221370951647\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.6204619630463672\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 91 rul difference: 1.6204619630463672.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       0\n",
      "Test RUL:        1\n",
      "RUL difference:  1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 92 rul difference: 1.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       9\n",
      "Test RUL:        1\n",
      "RUL difference:  8.61142583786212\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 97 rul difference: 8.61142583786212.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       2.802665199548005\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.7511648681465415\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 99 rul difference: 1.7511648681465415.\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 5.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141.59211006596712"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_rul_diff = 0\n",
    "\n",
    "for engineid in df_testing_pca.index.unique():\n",
    "    rul_difference = find_for_engineid_lowest_loss(df_training_with_hi_and_exp, \n",
    "                                                   df_testing_pca[df_testing_pca.index == engineid])\n",
    "    print('\\n\\n\\nEngine id {} rul difference: {}.\\n\\n\\n'.format(engineid, rul_difference))\n",
    "    \n",
    "    \n",
    "    total_rul_diff += rul_difference\n",
    "    \n",
    "total_rul_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test dataframe includes the following engine ids: [6, 10, 12, 14, 15, 19, 24, 36, 41, 59, 60, 63, 64, 67, 75, 78, 82, 96, 97, 99].\n",
      "\n",
      "We sliced the test dataframe into the following slices: \n",
      "\n",
      "Engine Id 6 filtered on index : [13, 84].\n",
      "This slice has a length of 71.\n",
      "The original total length of the engine id was 188.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 10 filtered on index : [10, 164].\n",
      "This slice has a length of 154.\n",
      "The original total length of the engine id was 222.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 12 filtered on index : [23, 104].\n",
      "This slice has a length of 81.\n",
      "The original total length of the engine id was 170.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 14 filtered on index : [13, 111].\n",
      "This slice has a length of 98.\n",
      "The original total length of the engine id was 180.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 15 filtered on index : [7, 124].\n",
      "This slice has a length of 117.\n",
      "The original total length of the engine id was 207.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 19 filtered on index : [52, 106].\n",
      "This slice has a length of 54.\n",
      "The original total length of the engine id was 158.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 24 filtered on index : [53, 91].\n",
      "This slice has a length of 38.\n",
      "The original total length of the engine id was 147.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 36 filtered on index : [4, 96].\n",
      "This slice has a length of 92.\n",
      "The original total length of the engine id was 158.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 41 filtered on index : [4, 115].\n",
      "This slice has a length of 111.\n",
      "The original total length of the engine id was 216.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 59 filtered on index : [46, 176].\n",
      "This slice has a length of 130.\n",
      "The original total length of the engine id was 231.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 60 filtered on index : [20, 97].\n",
      "This slice has a length of 77.\n",
      "The original total length of the engine id was 172.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 63 filtered on index : [2, 83].\n",
      "This slice has a length of 81.\n",
      "The original total length of the engine id was 174.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 64 filtered on index : [21, 147].\n",
      "This slice has a length of 126.\n",
      "The original total length of the engine id was 283.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 67 filtered on index : [77, 256].\n",
      "This slice has a length of 179.\n",
      "The original total length of the engine id was 313.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 75 filtered on index : [44, 118].\n",
      "This slice has a length of 74.\n",
      "The original total length of the engine id was 229.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 78 filtered on index : [56, 165].\n",
      "This slice has a length of 109.\n",
      "The original total length of the engine id was 231.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 82 filtered on index : [3, 122].\n",
      "This slice has a length of 119.\n",
      "The original total length of the engine id was 214.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 96 filtered on index : [46, 137].\n",
      "This slice has a length of 91.\n",
      "The original total length of the engine id was 336.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 97 filtered on index : [35, 134].\n",
      "This slice has a length of 99.\n",
      "The original total length of the engine id was 202.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 99 filtered on index : [2, 59].\n",
      "This slice has a length of 57.\n",
      "The original total length of the engine id was 185.\n",
      "------------------------------------------------\n",
      "\n",
      "Wall time: 364 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create split\n",
    "df_training, df_testing = load_add_rul_filter_and_norm_data(percentage_test_set=0.2)\n",
    "\n",
    "# Extract random slice of dataframe\n",
    "df_testing = extract_part_test_data(df_testing, create_amount_of_random_numbers = 6, distance_of_max_length = 50)\n",
    "\n",
    "# Extract slopes\n",
    "df_slopes = slopes_all_engine(df_training)\n",
    "\n",
    "# Reduce the dimensionalities to 3 dimensions\n",
    "df_training_pca, df_testing_pca = perform_pca(df_slopes, df_training, df_testing, keep_rul_in_test = True)\n",
    "\n",
    "# Train model to predict Health Indicator\n",
    "gekke_model = train_health_indictor_model(df_training_pca)\n",
    "\n",
    "# Add health indicator\n",
    "df_training_pca['hi_pred'] = gekke_model.predict(df_training_pca[['pca1', 'pca2', 'pca3']])\n",
    "df_testing_pca['hi_pred']  = gekke_model.predict(df_testing_pca[['pca1', 'pca2', 'pca3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add exp model\n",
    "df_training_with_hi_and_exp = add_exponential_fits(df_training_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss:       0.3564419177068627\n",
      "Train RUL:       91\n",
      "Test RUL:        105\n",
      "RUL difference:  13.932144743804471\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 6 rul difference: 13.932144743804471.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       9.6451814404716\n",
      "Train RUL:       52\n",
      "Test RUL:        59\n",
      "RUL difference:  6.850879786596188\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 10 rul difference: 6.850879786596188.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.5212735239348429\n",
      "Train RUL:       84\n",
      "Test RUL:        67\n",
      "RUL difference:  17.24065659919313\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 12 rul difference: 17.24065659919313.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.5285684919135368\n",
      "Train RUL:       63\n",
      "Test RUL:        70\n",
      "RUL difference:  6.736305536564075\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 14 rul difference: 6.736305536564075.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       6.858703190616704\n",
      "Train RUL:       90\n",
      "Test RUL:        84\n",
      "RUL difference:  6.040848898418062\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 15 rul difference: 6.040848898418062.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.3159980862487085\n",
      "Train RUL:       61\n",
      "Test RUL:        53\n",
      "RUL difference:  8.001808942090427\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 19 rul difference: 8.001808942090427.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.16407185239909008\n",
      "Train RUL:       70\n",
      "Test RUL:        57\n",
      "RUL difference:  13.386484856268481\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 24 rul difference: 13.386484856268481.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.5410305261732472\n",
      "Train RUL:       78\n",
      "Test RUL:        63\n",
      "RUL difference:  15.25573555190968\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 36 rul difference: 15.25573555190968.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       3.8565864019485883\n",
      "Train RUL:       105\n",
      "Test RUL:        102\n",
      "RUL difference:  3.693652431216506\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 41 rul difference: 3.693652431216506.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       5.012104770436464\n",
      "Train RUL:       52\n",
      "Test RUL:        56\n",
      "RUL difference:  3.9930141657864766\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 59 rul difference: 3.9930141657864766.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.32712827554841195\n",
      "Train RUL:       95\n",
      "Test RUL:        76\n",
      "RUL difference:  19.596412737589645\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 60 rul difference: 19.596412737589645.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.5725907614793747\n",
      "Train RUL:       99\n",
      "Test RUL:        92\n",
      "RUL difference:  7.665008586986659\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 63 rul difference: 7.665008586986659.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.7289245628570374\n",
      "Train RUL:       90\n",
      "Test RUL:        137\n",
      "RUL difference:  46.4506000942896\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 64 rul difference: 46.4506000942896.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.602698829626228\n",
      "Train RUL:       51\n",
      "Test RUL:        58\n",
      "RUL difference:  6.092850098641321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 67 rul difference: 6.092850098641321.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.360780792748862\n",
      "Train RUL:       89\n",
      "Test RUL:        112\n",
      "RUL difference:  22.00591970178023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 75 rul difference: 22.00591970178023.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       3.8441303231467074\n",
      "Train RUL:       74\n",
      "Test RUL:        67\n",
      "RUL difference:  7.193006446193095\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 78 rul difference: 7.193006446193095.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       9.034141107420503\n",
      "Train RUL:       112\n",
      "Test RUL:        93\n",
      "RUL difference:  19.51972364040519\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 82 rul difference: 19.51972364040519.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.2597757322520502\n",
      "Train RUL:       169\n",
      "Test RUL:        200\n",
      "RUL difference:  30.580814601832827\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 96 rul difference: 30.580814601832827.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.4626459135819938\n",
      "Train RUL:       124\n",
      "Test RUL:        69\n",
      "RUL difference:  55.079191762108806\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 97 rul difference: 55.079191762108806.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.8691300868861006\n",
      "Train RUL:       109\n",
      "Test RUL:        127\n",
      "RUL difference:  17.86744683200942\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 99 rul difference: 17.86744683200942.\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 34.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "327.1825060136843"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_rul_diff = 0\n",
    "\n",
    "for engineid in df_testing_pca.index.unique():\n",
    "    rul_difference = find_for_engineid_lowest_loss(df_training_with_hi_and_exp, \n",
    "                                                   df_testing_pca[df_testing_pca.index == engineid])\n",
    "    print('\\n\\n\\nEngine id {} rul difference: {}.\\n\\n\\n'.format(engineid, rul_difference))\n",
    "    \n",
    "    \n",
    "    total_rul_diff += rul_difference\n",
    "    \n",
    "total_rul_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "# Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-07d5946ae326>\u001b[0m in \u001b[0;36mfinal_prediction\u001b[1;34m(dataframe_training, dataframe_schedule)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Add exponential fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mdataframe_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_exponential_fits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c0f7a41539e7>\u001b[0m in \u001b[0;36madd_exponential_fits\u001b[1;34m(dataframe_with_health_index)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mengine_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_exponential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6877\u001b[0m         )\n\u001b[1;32m-> 6878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6880\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[1;32m--> 296\u001b[1;33m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c0f7a41539e7>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mengine_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_exponential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c0f7a41539e7>\u001b[0m in \u001b[0;36mget_exponential\u001b[1;34m(timestep, row)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_exponential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mexp_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rul'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mexp_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mexp_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_exp_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c0f7a41539e7>\u001b[0m in \u001b[0;36mexp_func\u001b[1;34m(x, a, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_exponential_fits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe_with_health_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexp_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_exp_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train               = load_dataset('../data/DataTrain.txt')\n",
    "df_train               = df_train.set_index('engine_id')\n",
    "df_train.loc[: ,'rul'] = get_ruls(df_train)\n",
    "\n",
    "df_schedule = load_dataset('../data/DataSchedule.txt')\n",
    "df_schedule = df_schedule.set_index('engine_id')\n",
    "\n",
    "predictions = final_prediction(df_train, df_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
