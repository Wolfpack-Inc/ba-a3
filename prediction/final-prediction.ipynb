{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "sys.path.append('..')\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from load_data import *\n",
    "\n",
    "from numpy.random import default_rng\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# if not sys.warnoptions:\n",
    "#     import warnings\n",
    "#     warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_part_test_data(dataframe_test, create_amount_of_random_numbers = 6, distance_of_max_length = 0):\n",
    "    \"\"\"\n",
    "    This function takes as input the df_test and creates for each engine id\n",
    "    random amount of numbers (create_amount_of_random_numbers). Then it sorts \n",
    "    those numbers and takes the lowest and biggest number (e.g. 4 and 142). It\n",
    "    uses those numbers to slice a random part.\n",
    "    \n",
    "    We also can add the parameter 'distance_of_max_length'. This parameter allows\n",
    "    us to for example set a limit of -50 of the maximum length of an engine id. If\n",
    "    the engine_id has e.g. length 230 (where the RUL is 0), we can set the limit to\n",
    "    finding random number between 0 and 180 (instead of 230).\n",
    "    \"\"\"\n",
    "    # Extract all the unique engine ids and their maximum length in the original dataframe\n",
    "    unique_engine_ids = dataframe_test.index.unique()\n",
    "    amount_of_ruls    = {engine_id : dataframe_test[dataframe_test.index == engine_id]['cycle'].max()\n",
    "                         for engine_id in unique_engine_ids}\n",
    "    \n",
    "    \n",
    "    # Loop over all engine ids and their length in the original dataframe_test\n",
    "    print('The test dataframe includes the following engine ids: {}.\\n'.format(list(unique_engine_ids)))\n",
    "    print('We sliced the test dataframe into the following slices: \\n')\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    for engine_id, max_length in amount_of_ruls.items():\n",
    "        random_numbers = np.random.randint(0, (max_length - 1 - distance_of_max_length), create_amount_of_random_numbers)\n",
    "        random_numbers_sorted = np.sort(random_numbers, axis=None)\n",
    "        print('Engine Id {} filtered on index : {}.'.format(engine_id, [random_numbers_sorted[0], random_numbers_sorted[-1]]))\n",
    "        print('This slice has a length of {}.'.format(random_numbers_sorted[-1] - random_numbers_sorted[0]))\n",
    "        print('The original total length of the engine id was {}.'.format(amount_of_ruls[engine_id]))\n",
    "        print('------------------------------------------------\\n')\n",
    "        \n",
    "        df_filtered = dataframe_test[dataframe_test.index == engine_id]\n",
    "        df_filtered = df_filtered.iloc[random_numbers_sorted[0] : random_numbers_sorted[-1]]\n",
    "        \n",
    "        new_df = new_df.append(df_filtered)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ruls(dataframe):\n",
    "    \"\"\"\n",
    "    Get the ruls of the engines\n",
    "    \"\"\"\n",
    "    # Try to drop max cycle to prevent an error\n",
    "    dataframe = dataframe.drop('max_cycle', 1, errors='ignore')\n",
    "    \n",
    "    # The max cycle of each engine\n",
    "    max_cycle = dataframe.groupby('engine_id').agg({'cycle': 'max'}).rename({'cycle': 'max_cycle'}, axis=1)\n",
    "    \n",
    "    # Add the max cycle to the dataframe\n",
    "    dataframe = dataframe.join(max_cycle, on='engine_id', )\n",
    "    \n",
    "    # Ruls are max cycle minus current cycle (plus 1)\n",
    "    ruls = (dataframe['max_cycle'] - dataframe['cycle'] + 1).values\n",
    "    \n",
    "    return ruls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_add_rul_filter_and_norm_data(percentage_test_set, path = '../data/DataTrain.txt'):\n",
    "    df = load_dataset(path)\n",
    "    df = df.set_index('engine_id')\n",
    "    \n",
    "    # Based on the analysing the slopes we found that the following sensors had\n",
    "    # showed a trend and had the highest average slope. We focus on the sensors \n",
    "    # with higher slopes because this makes it easier to distinguish the different RULs.\n",
    "    df = df[['cycle', 's4', 's3', 's17', 's7', 's12', 's2']]\n",
    "    df.loc[:, 'rul'] = get_ruls(df)\n",
    "    \n",
    "    # Calculate percentage test set\n",
    "    unique_engine_ids = df.index.unique()\n",
    "    \n",
    "    engine_ids_for_test_set = default_rng().choice(unique_engine_ids,\n",
    "                                                   size = int(max(unique_engine_ids) * percentage_test_set), \n",
    "                                                   replace=False)\n",
    "    \n",
    "    # Split data into df_train and df_test\n",
    "    df_train = df[~df.index.isin(engine_ids_for_test_set)]\n",
    "    df_test  = df[df.index.isin(engine_ids_for_test_set)]\n",
    "    \n",
    "    # Normalize both dataframes\n",
    "    scaler = StandardScaler()\n",
    "    df_train.iloc[:, 1:-1] = scaler.fit_transform(df_train.iloc[:, 1:-1])\n",
    "    df_test.iloc[:, 1:-1]  = scaler.transform(df_test.iloc[:, 1:-1])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slopes_all_engine(training_dataframe):\n",
    "    \"\"\"\n",
    "    Get the sensor slopes of all engines.\n",
    "    \"\"\"\n",
    "    def get_training_data(dataframe, engine_id, sensor_cols):\n",
    "        # X data\n",
    "        X = dataframe.loc[engine_id, 'rul'].values\n",
    "        X = X.reshape(-1, 1)\n",
    "\n",
    "        # y data\n",
    "        y = dataframe.loc[engine_id, sensor_cols].values\n",
    "\n",
    "        return (X, y)\n",
    "    \n",
    "    def slopes_of_engine(X, y):\n",
    "        \"\"\"\n",
    "        Fit a linear model on the sensor values of one engine\n",
    "        \"\"\"\n",
    "        # Create a linear model\n",
    "        linear_model = LinearRegression()\n",
    "\n",
    "        # Fit the model\n",
    "        linear_model.fit(X, y)\n",
    "\n",
    "        # Get slopes\n",
    "        slopes = linear_model.coef_[:,0]\n",
    "\n",
    "        return slopes\n",
    "    \n",
    "    # Loop over all the engines and calculate the slopes.\n",
    "    engine_slopes = {}\n",
    "    sensor_cols = training_dataframe.columns[1: -1].tolist()\n",
    "    \n",
    "    for engine_id in training_dataframe.index.unique():\n",
    "        X, y = get_training_data(training_dataframe, engine_id, sensor_cols)\n",
    "        slopes = slopes_of_engine(X, y)\n",
    "        \n",
    "        engine_slopes[engine_id] = slopes\n",
    "        \n",
    "    df_engine_slopes = pd.DataFrame(engine_slopes).T\n",
    "\n",
    "    df_engine_slopes.columns = sensor_cols\n",
    "    df_engine_slopes.index.name = 'engine_id'\n",
    "\n",
    "    return df_engine_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(dataframe_with_engine_slopes, dataframe_training, dataframe_testing, \n",
    "                n_components = 3, keep_rul_in_test = True):\n",
    "    \"\"\"\n",
    "    Here we will perform the PCA on the training and test set.\n",
    "    \"\"\"\n",
    "    # Fit the PCA on the engine slopes to reduce the dimensionality.\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(dataframe_with_engine_slopes)\n",
    "        \n",
    "    # Apply PCA on the dataframes    \n",
    "    matrix_training = np.column_stack([dataframe_training[['cycle', 'rul']].values, pca.transform(dataframe_training.iloc[:, 1:-1])])   \n",
    "    df_pca_training = pd.DataFrame(matrix_training, index=dataframe_training.index, columns=['cycle', 'rul', 'pca1', 'pca2', 'pca3'])\n",
    "        \n",
    "    if keep_rul_in_test == True:\n",
    "        matrix_testing  = np.column_stack([dataframe_testing[['cycle', 'rul']].values, pca.transform(dataframe_testing.iloc[:, 1:-1])])\n",
    "        df_pca_testing  = pd.DataFrame(matrix_testing, index=dataframe_testing.index, columns=['cycle', 'rul', 'pca1', 'pca2', 'pca3'])\n",
    "\n",
    "    else: \n",
    "        matrix_testing  = np.column_stack([dataframe_testing[['cycle']].values, pca.transform(dataframe_testing.iloc[:, 1:])])\n",
    "        df_pca_testing  = pd.DataFrame(matrix_testing, index=dataframe_testing.index, columns=['cycle', 'pca1', 'pca2', 'pca3'])\n",
    "\n",
    "    return df_pca_training, df_pca_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_health_indictor_model(dataframe_training_with_pca_values, high_rul = 250, low_rul = 5):\n",
    "    \"\"\"\n",
    "    This function applies sensor fusing to the training data and returns a\n",
    "    trained model to make predictions.\n",
    "    \"\"\"\n",
    "    # Extract ruls\n",
    "    ruls     = dataframe_training_with_pca_values['rul'].values\n",
    "    \n",
    "    # Extract rows\n",
    "    idx_high_health = [ruls > high_rul][0]\n",
    "    idx_low_health  = [ruls <= low_rul][0]\n",
    "    \n",
    "    # PCA to perform sensor fusing on\n",
    "    high_health_data = dataframe_training_with_pca_values.loc[idx_high_health, ['pca1', 'pca2', 'pca3']]\n",
    "    low_health_data  = dataframe_training_with_pca_values.loc[idx_low_health, ['pca1', 'pca2', 'pca3']]\n",
    "    \n",
    "    # concatenate high HI and Low HI data\n",
    "    X_health = np.concatenate((high_health_data, low_health_data),axis=0)\n",
    "\n",
    "    # target for the fused signal [ just 0 or 1 for failed ans healthy]\n",
    "    y_one = np.ones(high_health_data.shape[0])\n",
    "    y_zero = np.zeros(low_health_data.shape[0])\n",
    "\n",
    "    # concatenate high HI and Low HI target\n",
    "    y_health = np.concatenate((y_one, y_zero),axis=0)\n",
    "    \n",
    "    # Linear regression\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_health, y_health)\n",
    "    \n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_exponential_fits(dataframe_with_health_index):\n",
    "    def exp_func(x, a, b):\n",
    "        return a * (np.exp(b * -x)-1)\n",
    "\n",
    "    def find_exp_params(dataframe):\n",
    "        exp_params = np.zeros((dataframe.index.nunique(), 2))\n",
    "\n",
    "        # Loop through the engines\n",
    "        for idx, (engine_id, engine) in enumerate(dataframe.groupby('engine_id')):\n",
    "            x = engine['rul']\n",
    "            y = savgol_filter(engine['hi_pred'], 25, 1)\n",
    "\n",
    "            popt, _ = curve_fit(exp_func, x, y)\n",
    "\n",
    "            exp_params[idx, :] = popt\n",
    "\n",
    "        return exp_params\n",
    "\n",
    "    def get_exponential(timestep, row):\n",
    "        return exp_func(timestep['rul'], *exp_params[row, :])\n",
    "\n",
    "    exp_params = find_exp_params(dataframe_with_health_index)\n",
    "\n",
    "    dataframe_with_health_index['exp'] = 0\n",
    "\n",
    "    for index, engine_id in enumerate(dataframe_with_health_index.index.unique()):\n",
    "        indexes = dataframe_with_health_index[dataframe_with_health_index.index == engine_id].index\n",
    "        dataframe_with_health_index.loc[indexes, 'exp'] = dataframe_with_health_index.loc[indexes].apply(lambda x: get_exponential(x, index), axis =1)\n",
    "    \n",
    "    return dataframe_with_health_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rul_based_on_weighted_ssd(list_with_ssd_and_rul, extract_best_x = 10):\n",
    "    \"\"\"\n",
    "    This function makes based on a nested list [(ssd1, rul1), ... , (ssdN, rulN)]\n",
    "    a weighted prediction based on the ssd.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dataframe of the nested list\n",
    "    df_ssd_and_rul = pd.DataFrame(list_with_ssd_and_rul, columns=['ssd', 'rul'])\n",
    "        \n",
    "    # Sort the dataframe based on the ssd and extract top X (extract_best_x)\n",
    "    df_ssd_and_rul = df_ssd_and_rul.sort_values('ssd').iloc[ : extract_best_x]\n",
    "    \n",
    "    # Add percentage ssd of total\n",
    "    sum_ssd = df_ssd_and_rul['ssd'].sum()\n",
    "    df_ssd_and_rul['percentage_of_total'] = df_ssd_and_rul['ssd'] / sum_ssd\n",
    "    \n",
    "    # Make weighted predictions\n",
    "    weighted_prediction = sum(df_ssd_and_rul['rul'] * df_ssd_and_rul['percentage_of_total'])\n",
    "    \n",
    "    # Return prediction\n",
    "    return weighted_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_for_engineid_lowest_loss(dataframe_training, \n",
    "                                  dataframe_testing_engineid,\n",
    "                                  make_prediction_only = False):\n",
    "    \n",
    "    results = list()\n",
    "    length    = len(dataframe_testing_engineid)\n",
    "    \n",
    "    # We will look in each engine (of dataframe_training) for the lowest loss.\n",
    "    # When we find it, we will store it with the predicted RUL. This allows us \n",
    "    # to make predictions taking into account all the engineids.\n",
    "    for engine_id in dataframe_training.index.unique():\n",
    "        filtered_df = dataframe_training[dataframe_training.index == engine_id]\n",
    "        best_loss   = np.inf\n",
    "        best_train_slice = list()\n",
    "        \n",
    "        # Loop over each array in the filtered dataframe and try to find the \n",
    "        # best 'exp' where the loss is the lowest.\n",
    "        for row_index in range(0, len(filtered_df) - length):\n",
    "            train_slice = filtered_df.iloc[row_index : (row_index+length)]\n",
    "            train_health_index = train_slice['exp'].values\n",
    "            test_health_index  = dataframe_testing_engineid['hi_pred'].values\n",
    "\n",
    "            loss = np.sum((train_health_index - test_health_index) ** 2)\n",
    "\n",
    "            if loss < best_loss:\n",
    "                best_loss        = loss\n",
    "                best_train_slice = train_slice\n",
    "                \n",
    "        # If we couldn't find any good fit on the 'exp' in this engine id, skip the\n",
    "        # appending to the results.\n",
    "        if best_loss == np.inf:\n",
    "            continue\n",
    "            \n",
    "        # Add the result (loss and the RUL)\n",
    "        results.append([best_loss, int(best_train_slice.iloc[-1]['rul'])])\n",
    "        \n",
    "    # Make a weighted prediction based on the nested list\n",
    "    weighted_prediction = predict_rul_based_on_weighted_ssd(results)\n",
    "    \n",
    "    if make_prediction_only == False:\n",
    "        best_rul_difference = abs(int(dataframe_testing_engineid.iloc[-1]['rul']) - weighted_prediction)\n",
    "\n",
    "        print('Best loss:      ', best_loss)\n",
    "        print('Train RUL:      ', int(weighted_prediction))\n",
    "        print('Test RUL:       ', int(dataframe_testing_engineid.iloc[-1]['rul']))\n",
    "        print('RUL difference: ', best_rul_difference)\n",
    "        print('\\n')    \n",
    "            \n",
    "        return best_rul_difference\n",
    "    \n",
    "    else:\n",
    "        return weighted_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prediction(dataframe_training, dataframe_schedule):\n",
    "    \"\"\"\n",
    "    This function makes a prediction on the dataframe_schedule using the\n",
    "    dataframe_training.\n",
    "    \n",
    "    To make a prediction, we apply the following steps:\n",
    "    1. Extract the relevant columns from both tables.\n",
    "    2. Calculate the slopes of the dataframe_training.\n",
    "    3. Apply PCA and transform both dataframe_training and dataframe_schedule.\n",
    "    4. Train a linear model to predict the health indicators.\n",
    "    5. Predict the health indicators (hi_pred) of both tables.\n",
    "    6. Add fit an exponential model on the hi_pred of dataframe_training (exp).\n",
    "    7. Try to fit each engine_ids hi_pred in the dataframe_schedule on the best\n",
    "       suiting 'exp'. Based on the best fit we will predict the RUL.\n",
    "    \"\"\"\n",
    "    # Extract the relevant columns from both tables\n",
    "    columns = ['cycle', 's4', 's3', 's17', 's7', 's12', 's2', 'rul']\n",
    "    \n",
    "    dataframe_training = dataframe_training[columns]\n",
    "    dataframe_schedule = dataframe_schedule[columns[: -1]]\n",
    "            \n",
    "    # Calculate slopes of the dataframe_training\n",
    "    dataframe_training_slopes = slopes_all_engine(dataframe_training)\n",
    "    \n",
    "    # Reduce dimensionalities with PCA\n",
    "    dataframe_training_pca, dataframe_schedule_pca = perform_pca(dataframe_training_slopes, \n",
    "                                                                 dataframe_training, \n",
    "                                                                 dataframe_schedule, \n",
    "                                                                 keep_rul_in_test = False)\n",
    "    \n",
    "    # Train linear model\n",
    "    trained_model = train_health_indictor_model(dataframe_training_pca)\n",
    "        \n",
    "    # Predict health indicator\n",
    "    dataframe_training['hi_pred'] = trained_model.predict(dataframe_training_pca[['pca1', 'pca2', 'pca3']])\n",
    "    dataframe_schedule['hi_pred'] = trained_model.predict(dataframe_schedule_pca[['pca1', 'pca2', 'pca3']])\n",
    "    \n",
    "    # Add exponential fit\n",
    "    dataframe_training = add_exponential_fits(dataframe_training)\n",
    "    \n",
    "    # Make predictions\n",
    "    results = {}\n",
    "    \n",
    "    for engineid in dataframe_training.index.unique():\n",
    "        results[engineid] = find_for_engineid_lowest_loss(dataframe_training, \n",
    "                                                          dataframe_schedule[dataframe_schedule.index == engineid],\n",
    "                                                          make_prediction_only = True)    \n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 501 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create split\n",
    "df_training, df_testing = load_add_rul_filter_and_norm_data(percentage_test_set=0.2)\n",
    "\n",
    "# Extract random slice of dataframe\n",
    "# df_testing = extract_part_test_data(df_testing, create_amount_of_random_numbers = 6, distance_of_max_length = 50)\n",
    "\n",
    "# Extract slopes\n",
    "df_slopes = slopes_all_engine(df_training)\n",
    "\n",
    "# Reduce the dimensionalities to 3 dimensions\n",
    "df_training_pca, df_testing_pca = perform_pca(df_slopes, df_training, df_testing, keep_rul_in_test = True)\n",
    "\n",
    "# Train model to predict Health Indicator\n",
    "gekke_model = train_health_indictor_model(df_training_pca)\n",
    "\n",
    "# Add health indicator\n",
    "df_training_pca['hi_pred'] = gekke_model.predict(df_training_pca[['pca1', 'pca2', 'pca3']])\n",
    "df_testing_pca['hi_pred']  = gekke_model.predict(df_testing_pca[['pca1', 'pca2', 'pca3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add exp model\n",
    "df_training_with_hi_and_exp = add_exponential_fits(df_training_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss:       3.0308453366532024\n",
      "Train RUL:       3\n",
      "Test RUL:        1\n",
      "RUL difference:  2.546713681890184\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 1 rul difference: 2.546713681890184.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       21\n",
      "Test RUL:        1\n",
      "RUL difference:  20.74466328009513\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 5 rul difference: 20.74466328009513.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       3.199710589750099\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.45039647083615\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 6 rul difference: 1.45039647083615.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       6\n",
      "Test RUL:        1\n",
      "RUL difference:  5.424317452691452\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 15 rul difference: 5.424317452691452.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       20\n",
      "Test RUL:        1\n",
      "RUL difference:  19.92087443149913\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 17 rul difference: 19.92087443149913.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       2\n",
      "Test RUL:        1\n",
      "RUL difference:  1.2078468601126686\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 22 rul difference: 1.2078468601126686.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.1002115021988206\n",
      "Train RUL:       5\n",
      "Test RUL:        1\n",
      "RUL difference:  4.054107995530423\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 23 rul difference: 4.054107995530423.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.1942602361159895\n",
      "Train RUL:       4\n",
      "Test RUL:        1\n",
      "RUL difference:  3.2475795193351953\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 27 rul difference: 3.2475795193351953.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       8.121586915593538\n",
      "Train RUL:       5\n",
      "Test RUL:        1\n",
      "RUL difference:  4.43497862766102\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 28 rul difference: 4.43497862766102.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       2.160810963528093\n",
      "Train RUL:       8\n",
      "Test RUL:        1\n",
      "RUL difference:  7.619967111860891\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 38 rul difference: 7.619967111860891.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       4.656650296176539\n",
      "Train RUL:       5\n",
      "Test RUL:        1\n",
      "RUL difference:  4.195980734794642\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 44 rul difference: 4.195980734794642.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       16\n",
      "Test RUL:        1\n",
      "RUL difference:  15.191596242587888\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 51 rul difference: 15.191596242587888.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       2.420869208986968\n",
      "Train RUL:       4\n",
      "Test RUL:        1\n",
      "RUL difference:  3.8577084519598595\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 57 rul difference: 3.8577084519598595.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       2.1109650943843294\n",
      "Train RUL:       4\n",
      "Test RUL:        1\n",
      "RUL difference:  3.89848115718478\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 58 rul difference: 3.89848115718478.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       3\n",
      "Test RUL:        1\n",
      "RUL difference:  2.3263016385053312\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 76 rul difference: 2.3263016385053312.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       32\n",
      "Test RUL:        1\n",
      "RUL difference:  31.058423555029947\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 78 rul difference: 31.058423555029947.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       10.547125996189749\n",
      "Train RUL:       5\n",
      "Test RUL:        1\n",
      "RUL difference:  4.180834995266026\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 79 rul difference: 4.180834995266026.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       2.521754390974737\n",
      "Train RUL:       10\n",
      "Test RUL:        1\n",
      "RUL difference:  9.948197616940895\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 80 rul difference: 9.948197616940895.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       inf\n",
      "Train RUL:       7\n",
      "Test RUL:        1\n",
      "RUL difference:  6.630489613265342\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 81 rul difference: 6.630489613265342.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.9881439673409709\n",
      "Train RUL:       4\n",
      "Test RUL:        1\n",
      "RUL difference:  3.433559306661408\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 85 rul difference: 3.433559306661408.\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 14.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "155.37301874370837"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_rul_diff = 0\n",
    "\n",
    "for engineid in df_testing_pca.index.unique():\n",
    "    rul_difference = find_for_engineid_lowest_loss(df_training_with_hi_and_exp, \n",
    "                                                   df_testing_pca[df_testing_pca.index == engineid])\n",
    "    print('\\n\\n\\nEngine id {} rul difference: {}.\\n\\n\\n'.format(engineid, rul_difference))\n",
    "    \n",
    "    \n",
    "    total_rul_diff += rul_difference\n",
    "    \n",
    "total_rul_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test dataframe includes the following engine ids: [3, 4, 5, 6, 12, 13, 14, 15, 24, 26, 31, 39, 40, 41, 48, 52, 71, 79, 80, 87].\n",
      "\n",
      "We sliced the test dataframe into the following slices: \n",
      "\n",
      "Engine Id 3 filtered on index : [19, 112].\n",
      "This slice has a length of 93.\n",
      "The original total length of the engine id was 179.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 4 filtered on index : [6, 72].\n",
      "This slice has a length of 66.\n",
      "The original total length of the engine id was 189.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 5 filtered on index : [11, 197].\n",
      "This slice has a length of 186.\n",
      "The original total length of the engine id was 269.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 6 filtered on index : [56, 136].\n",
      "This slice has a length of 80.\n",
      "The original total length of the engine id was 188.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 12 filtered on index : [8, 102].\n",
      "This slice has a length of 94.\n",
      "The original total length of the engine id was 170.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 13 filtered on index : [9, 83].\n",
      "This slice has a length of 74.\n",
      "The original total length of the engine id was 163.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 14 filtered on index : [22, 116].\n",
      "This slice has a length of 94.\n",
      "The original total length of the engine id was 180.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 15 filtered on index : [18, 142].\n",
      "This slice has a length of 124.\n",
      "The original total length of the engine id was 207.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 24 filtered on index : [6, 92].\n",
      "This slice has a length of 86.\n",
      "The original total length of the engine id was 147.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 26 filtered on index : [66, 137].\n",
      "This slice has a length of 71.\n",
      "The original total length of the engine id was 199.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 31 filtered on index : [1, 170].\n",
      "This slice has a length of 169.\n",
      "The original total length of the engine id was 234.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 39 filtered on index : [1, 71].\n",
      "This slice has a length of 70.\n",
      "The original total length of the engine id was 128.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 40 filtered on index : [43, 130].\n",
      "This slice has a length of 87.\n",
      "The original total length of the engine id was 188.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 41 filtered on index : [4, 121].\n",
      "This slice has a length of 117.\n",
      "The original total length of the engine id was 216.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 48 filtered on index : [3, 173].\n",
      "This slice has a length of 170.\n",
      "The original total length of the engine id was 231.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 52 filtered on index : [2, 158].\n",
      "This slice has a length of 156.\n",
      "The original total length of the engine id was 213.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 71 filtered on index : [18, 119].\n",
      "This slice has a length of 101.\n",
      "The original total length of the engine id was 208.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 79 filtered on index : [23, 145].\n",
      "This slice has a length of 122.\n",
      "The original total length of the engine id was 199.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 80 filtered on index : [39, 130].\n",
      "This slice has a length of 91.\n",
      "The original total length of the engine id was 185.\n",
      "------------------------------------------------\n",
      "\n",
      "Engine Id 87 filtered on index : [18, 102].\n",
      "This slice has a length of 84.\n",
      "The original total length of the engine id was 178.\n",
      "------------------------------------------------\n",
      "\n",
      "Wall time: 562 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create split\n",
    "df_training, df_testing = load_add_rul_filter_and_norm_data(percentage_test_set=0.2)\n",
    "\n",
    "# Extract random slice of dataframe\n",
    "df_testing = extract_part_test_data(df_testing, create_amount_of_random_numbers = 6, distance_of_max_length = 50)\n",
    "\n",
    "# Extract slopes\n",
    "df_slopes = slopes_all_engine(df_training)\n",
    "\n",
    "# Reduce the dimensionalities to 3 dimensions\n",
    "df_training_pca, df_testing_pca = perform_pca(df_slopes, df_training, df_testing, keep_rul_in_test = True)\n",
    "\n",
    "# Train model to predict Health Indicator\n",
    "gekke_model = train_health_indictor_model(df_training_pca)\n",
    "\n",
    "# Add health indicator\n",
    "df_training_pca['hi_pred'] = gekke_model.predict(df_training_pca[['pca1', 'pca2', 'pca3']])\n",
    "df_testing_pca['hi_pred']  = gekke_model.predict(df_testing_pca[['pca1', 'pca2', 'pca3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add exp model\n",
    "df_training_with_hi_and_exp = add_exponential_fits(df_training_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss:       2.1786007590706435\n",
      "Train RUL:       93\n",
      "Test RUL:        68\n",
      "RUL difference:  25.28940068221341\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 3 rul difference: 25.28940068221341.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.2522850430216161\n",
      "Train RUL:       145\n",
      "Test RUL:        118\n",
      "RUL difference:  27.305636696334545\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 4 rul difference: 27.305636696334545.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       23.821629515587695\n",
      "Train RUL:       62\n",
      "Test RUL:        73\n",
      "RUL difference:  10.000803844405112\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 5 rul difference: 10.000803844405112.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.7807953753270238\n",
      "Train RUL:       65\n",
      "Test RUL:        53\n",
      "RUL difference:  12.91118011787843\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 6 rul difference: 12.91118011787843.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.6931110479549051\n",
      "Train RUL:       87\n",
      "Test RUL:        69\n",
      "RUL difference:  18.480607180847613\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 12 rul difference: 18.480607180847613.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.4547290714641384\n",
      "Train RUL:       112\n",
      "Test RUL:        81\n",
      "RUL difference:  31.36541212834473\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 13 rul difference: 31.36541212834473.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.5083976132855937\n",
      "Train RUL:       72\n",
      "Test RUL:        65\n",
      "RUL difference:  7.654351059896257\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 14 rul difference: 7.654351059896257.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       6.199927293306375\n",
      "Train RUL:       68\n",
      "Test RUL:        66\n",
      "RUL difference:  2.3363183514249215\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 15 rul difference: 2.3363183514249215.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.6293377939688708\n",
      "Train RUL:       70\n",
      "Test RUL:        56\n",
      "RUL difference:  14.412796184222046\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 24 rul difference: 14.412796184222046.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.7204160115101262\n",
      "Train RUL:       107\n",
      "Test RUL:        63\n",
      "RUL difference:  44.98566438026144\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 26 rul difference: 44.98566438026144.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       13.040398872222667\n",
      "Train RUL:       69\n",
      "Test RUL:        65\n",
      "RUL difference:  4.0048829451095855\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 31 rul difference: 4.0048829451095855.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.3795550198406879\n",
      "Train RUL:       80\n",
      "Test RUL:        58\n",
      "RUL difference:  22.604530659318897\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 39 rul difference: 22.604530659318897.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.8603441577909999\n",
      "Train RUL:       63\n",
      "Test RUL:        59\n",
      "RUL difference:  4.669586663153822\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 40 rul difference: 4.669586663153822.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       4.444954600218015\n",
      "Train RUL:       93\n",
      "Test RUL:        96\n",
      "RUL difference:  2.864724690696818\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 41 rul difference: 2.864724690696818.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       13.758821985510872\n",
      "Train RUL:       73\n",
      "Test RUL:        59\n",
      "RUL difference:  14.136764212067916\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 48 rul difference: 14.136764212067916.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       1.1163906626302382\n",
      "Train RUL:       59\n",
      "Test RUL:        56\n",
      "RUL difference:  3.3798304026809305\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 52 rul difference: 3.3798304026809305.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.6622179337249761\n",
      "Train RUL:       101\n",
      "Test RUL:        90\n",
      "RUL difference:  11.544791426732957\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 71 rul difference: 11.544791426732957.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       4.997931163529534\n",
      "Train RUL:       50\n",
      "Test RUL:        55\n",
      "RUL difference:  4.305812487319159\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 79 rul difference: 4.305812487319159.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.7810727417728931\n",
      "Train RUL:       81\n",
      "Test RUL:        56\n",
      "RUL difference:  25.788407986561694\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 80 rul difference: 25.788407986561694.\n",
      "\n",
      "\n",
      "\n",
      "Best loss:       0.4421158512957664\n",
      "Train RUL:       88\n",
      "Test RUL:        77\n",
      "RUL difference:  11.057932097443455\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Engine id 87 rul difference: 11.057932097443455.\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 48.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "299.09943419691376"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_rul_diff = 0\n",
    "\n",
    "for engineid in df_testing_pca.index.unique():\n",
    "    rul_difference = find_for_engineid_lowest_loss(df_training_with_hi_and_exp, \n",
    "                                                   df_testing_pca[df_testing_pca.index == engineid])\n",
    "    print('\\n\\n\\nEngine id {} rul difference: {}.\\n\\n\\n'.format(engineid, rul_difference))\n",
    "    \n",
    "    \n",
    "    total_rul_diff += rul_difference\n",
    "    \n",
    "total_rul_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "# Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_train               = load_dataset('../data/DataTrain.txt')\n",
    "df_train               = df_train.set_index('engine_id')\n",
    "df_train.loc[: ,'rul'] = get_ruls(df_train)\n",
    "\n",
    "df_schedule = load_dataset('../data/DataSchedule.txt')\n",
    "df_schedule = df_schedule.set_index('engine_id')\n",
    "\n",
    "predictions = final_prediction(df_train, df_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
